{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNTkkF2BGm5PuXIpYOU7naR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7krXwTut7fj"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6fZ_98Kaokr",
        "outputId": "e1bb086c-970e-4f1f-b8d1-9a8d073a0129"
      },
      "source": [
        "data_path = '/content/data.txt'\n",
        "\n",
        "with open(data_path) as f:\n",
        "  text = f.read()\n",
        "\n",
        "print(text[:100])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yes To Life consists of three lectures that Viktor Frankl gave shortly after his release from the na\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAJXhsIFaovV",
        "outputId": "0dbbf7b8-3e95-4fca-c403-740efff4e848"
      },
      "source": [
        "corpus = text.lower().split('\\n')\n",
        "print(corpus[0])\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "word_index = tokenizer.word_index\n",
        "total_words = len(word_index) + 1"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yes to life consists of three lectures that viktor frankl gave shortly after his release from the nazi prison camps. \\n \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eew0G1kHciTL"
      },
      "source": [
        "input_sequences = []\n",
        "\n",
        "for line in corpus:\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1, len(token_list)):\n",
        "    n_gram_sequences = token_list[:i+1]\n",
        "    input_sequences.append(n_gram_sequences)\n",
        "\n",
        "max_sequence_len = 30\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycn3DyJnb6qC"
      },
      "source": [
        "input_sequences[0:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGuHwaKMcoaK"
      },
      "source": [
        "xs = input_sequences[:,:-1]\n",
        "ys = input_sequences[:,-1]\n",
        "labels = tf.keras.utils.to_categorical(ys, num_classes=total_words)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aSl9NLIdlgR",
        "outputId": "b036422d-5d69-41c4-a344-caaaf1dad95f"
      },
      "source": [
        "print(xs[0], ys[0])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0 45] 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgyNxxkudtvT",
        "outputId": "23fcf107-2237-4655-be92-32837fa3bec0"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Embedding(total_words, 32, input_length=max_sequence_len),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "  tf.keras.layers.LSTM(64),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(180, activation='relu'),\n",
        "  tf.keras.layers.Dense(360, activation='softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 30, 32)            11520     \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 30, 128)           49664     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 180)               23220     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 360)               65160     \n",
            "=================================================================\n",
            "Total params: 207,292\n",
            "Trainable params: 207,292\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXgeQ4egettK",
        "outputId": "a134c387-6fcd-4acd-926a-afe67769c6ba"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(xs, labels, epochs=100)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 29).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 29).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 29).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 29).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "26/26 [==============================] - 6s 45ms/step - loss: 5.7846 - accuracy: 0.0338\n",
            "Epoch 2/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 5.4178 - accuracy: 0.0471\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 5.3303 - accuracy: 0.0411\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 5.3129 - accuracy: 0.0447\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 5.3058 - accuracy: 0.0459\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 1s 45ms/step - loss: 5.2780 - accuracy: 0.0374\n",
            "Epoch 7/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 5.2284 - accuracy: 0.0459\n",
            "Epoch 8/100\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 5.0926 - accuracy: 0.0399\n",
            "Epoch 9/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 4.9562 - accuracy: 0.0350\n",
            "Epoch 10/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 4.8653 - accuracy: 0.0411\n",
            "Epoch 11/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 4.7896 - accuracy: 0.0519\n",
            "Epoch 12/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 4.6995 - accuracy: 0.0592\n",
            "Epoch 13/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 4.6104 - accuracy: 0.0652\n",
            "Epoch 14/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 4.5284 - accuracy: 0.0882\n",
            "Epoch 15/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 4.3998 - accuracy: 0.0870\n",
            "Epoch 16/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 4.2829 - accuracy: 0.0990\n",
            "Epoch 17/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 4.1855 - accuracy: 0.1002\n",
            "Epoch 18/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 4.0917 - accuracy: 0.1087\n",
            "Epoch 19/100\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 3.9984 - accuracy: 0.0906\n",
            "Epoch 20/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 3.9334 - accuracy: 0.1087\n",
            "Epoch 21/100\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 3.8409 - accuracy: 0.1075\n",
            "Epoch 22/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 3.7516 - accuracy: 0.1196\n",
            "Epoch 23/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 3.6531 - accuracy: 0.1244\n",
            "Epoch 24/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 3.5718 - accuracy: 0.1425\n",
            "Epoch 25/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 3.5176 - accuracy: 0.1329\n",
            "Epoch 26/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 3.4052 - accuracy: 0.1377\n",
            "Epoch 27/100\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 3.3503 - accuracy: 0.1486\n",
            "Epoch 28/100\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 3.3077 - accuracy: 0.1546\n",
            "Epoch 29/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 3.2414 - accuracy: 0.1606\n",
            "Epoch 30/100\n",
            "26/26 [==============================] - 1s 45ms/step - loss: 3.1469 - accuracy: 0.1606\n",
            "Epoch 31/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 3.0349 - accuracy: 0.1715\n",
            "Epoch 32/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 2.9783 - accuracy: 0.1981\n",
            "Epoch 33/100\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 3.0123 - accuracy: 0.1667\n",
            "Epoch 34/100\n",
            "26/26 [==============================] - 1s 45ms/step - loss: 2.9205 - accuracy: 0.1872\n",
            "Epoch 35/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 2.7919 - accuracy: 0.2162\n",
            "Epoch 36/100\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 2.6651 - accuracy: 0.2367\n",
            "Epoch 37/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 2.6219 - accuracy: 0.2572\n",
            "Epoch 38/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 2.5859 - accuracy: 0.2585\n",
            "Epoch 39/100\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 2.5745 - accuracy: 0.2452\n",
            "Epoch 40/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 2.5304 - accuracy: 0.2585\n",
            "Epoch 41/100\n",
            "26/26 [==============================] - 1s 48ms/step - loss: 2.4702 - accuracy: 0.2729\n",
            "Epoch 42/100\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 2.6169 - accuracy: 0.2295\n",
            "Epoch 43/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 2.5001 - accuracy: 0.2476\n",
            "Epoch 44/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 2.3102 - accuracy: 0.2959\n",
            "Epoch 45/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 2.1738 - accuracy: 0.3478\n",
            "Epoch 46/100\n",
            "26/26 [==============================] - 1s 45ms/step - loss: 2.0845 - accuracy: 0.3442\n",
            "Epoch 47/100\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 2.0608 - accuracy: 0.3696\n",
            "Epoch 48/100\n",
            "26/26 [==============================] - 1s 51ms/step - loss: 1.9945 - accuracy: 0.3684\n",
            "Epoch 49/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 1.9646 - accuracy: 0.3925\n",
            "Epoch 50/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 1.9310 - accuracy: 0.3829\n",
            "Epoch 51/100\n",
            "26/26 [==============================] - 1s 46ms/step - loss: 1.8729 - accuracy: 0.4070\n",
            "Epoch 52/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 1.7945 - accuracy: 0.4287\n",
            "Epoch 53/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 1.7231 - accuracy: 0.4698\n",
            "Epoch 54/100\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.6770 - accuracy: 0.4698\n",
            "Epoch 55/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 1.6601 - accuracy: 0.4734\n",
            "Epoch 56/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 1.6519 - accuracy: 0.4686\n",
            "Epoch 57/100\n",
            "26/26 [==============================] - 1s 45ms/step - loss: 1.5188 - accuracy: 0.5242\n",
            "Epoch 58/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 1.5042 - accuracy: 0.5072\n",
            "Epoch 59/100\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.4707 - accuracy: 0.5242\n",
            "Epoch 60/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 1.4148 - accuracy: 0.5507\n",
            "Epoch 61/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 1.3575 - accuracy: 0.5592\n",
            "Epoch 62/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 1.2733 - accuracy: 0.6063\n",
            "Epoch 63/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 1.2072 - accuracy: 0.6220\n",
            "Epoch 64/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 1.2051 - accuracy: 0.6099\n",
            "Epoch 65/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 1.1794 - accuracy: 0.6329\n",
            "Epoch 66/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 1.1089 - accuracy: 0.6534\n",
            "Epoch 67/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 1.0843 - accuracy: 0.6461\n",
            "Epoch 68/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 1.1171 - accuracy: 0.6486\n",
            "Epoch 69/100\n",
            "26/26 [==============================] - 1s 45ms/step - loss: 1.0475 - accuracy: 0.6691\n",
            "Epoch 70/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 1.1222 - accuracy: 0.6437\n",
            "Epoch 71/100\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 1.1029 - accuracy: 0.6341\n",
            "Epoch 72/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 1.0066 - accuracy: 0.6691\n",
            "Epoch 73/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 0.9187 - accuracy: 0.7114\n",
            "Epoch 74/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 0.8656 - accuracy: 0.7258\n",
            "Epoch 75/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 0.8174 - accuracy: 0.7415\n",
            "Epoch 76/100\n",
            "26/26 [==============================] - 1s 49ms/step - loss: 0.7312 - accuracy: 0.7874\n",
            "Epoch 77/100\n",
            "26/26 [==============================] - 1s 45ms/step - loss: 0.7259 - accuracy: 0.7886\n",
            "Epoch 78/100\n",
            "26/26 [==============================] - 1s 47ms/step - loss: 0.6979 - accuracy: 0.7874\n",
            "Epoch 79/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 0.6656 - accuracy: 0.7923\n",
            "Epoch 80/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 0.6296 - accuracy: 0.8116\n",
            "Epoch 81/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 0.6385 - accuracy: 0.7923\n",
            "Epoch 82/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 0.6110 - accuracy: 0.8140\n",
            "Epoch 83/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 0.5810 - accuracy: 0.8225\n",
            "Epoch 84/100\n",
            "26/26 [==============================] - 1s 45ms/step - loss: 0.5645 - accuracy: 0.8273\n",
            "Epoch 85/100\n",
            "26/26 [==============================] - 1s 46ms/step - loss: 0.5422 - accuracy: 0.8394\n",
            "Epoch 86/100\n",
            "26/26 [==============================] - 1s 48ms/step - loss: 0.5878 - accuracy: 0.8056\n",
            "Epoch 87/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 0.6321 - accuracy: 0.7959\n",
            "Epoch 88/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 0.6216 - accuracy: 0.7874\n",
            "Epoch 89/100\n",
            "26/26 [==============================] - 1s 45ms/step - loss: 0.6565 - accuracy: 0.7959\n",
            "Epoch 90/100\n",
            "26/26 [==============================] - 1s 46ms/step - loss: 0.6560 - accuracy: 0.7874\n",
            "Epoch 91/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 0.7464 - accuracy: 0.7548\n",
            "Epoch 92/100\n",
            "26/26 [==============================] - 1s 49ms/step - loss: 0.6691 - accuracy: 0.7766\n",
            "Epoch 93/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 0.6013 - accuracy: 0.7850\n",
            "Epoch 94/100\n",
            "26/26 [==============================] - 1s 45ms/step - loss: 0.5613 - accuracy: 0.8213\n",
            "Epoch 95/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 0.5179 - accuracy: 0.8635\n",
            "Epoch 96/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 0.4270 - accuracy: 0.8720\n",
            "Epoch 97/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 0.3607 - accuracy: 0.8949\n",
            "Epoch 98/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 0.3418 - accuracy: 0.9034\n",
            "Epoch 99/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 0.2921 - accuracy: 0.9239\n",
            "Epoch 100/100\n",
            "26/26 [==============================] - 1s 43ms/step - loss: 0.2755 - accuracy: 0.9360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwo9M-ube6kW",
        "outputId": "0040fb89-4491-43ae-e0cf-9b77c3861643"
      },
      "source": [
        "seed_text = 'the first time'\n",
        "next_words = 10\n",
        "\n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the first time frankl shares real examples of people that a has joy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuMcw2DOf0Tz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}